{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ORDER = [\"TYK2\", \"USP7\", \"D2R\", \"Mpro\"]\n",
    "MODEL_ORDER = [\"GP\", \"CP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from exs.ale.featurisers import Featuriser\n",
    "from typing import Callable\n",
    "from oekit.io import standardise_smiles\n",
    "\n",
    "def load_dataset(name: str, path: str, smiles_col: str, affinity_col: str, affinity_conversion: Callable) -> pd.DataFrame:\n",
    "    # load data\n",
    "    data = pd.read_csv(path)\n",
    "\n",
    "    # convert affinity to pXC50 scale\n",
    "    data['affinity'] = affinity_conversion(data[affinity_col])\n",
    "\n",
    "    # standardise column names and deduplicate\n",
    "    data = data.rename(columns={smiles_col: 'SMILES'})\n",
    "    data[\"SMILES\"] = data.SMILES.apply(standardise_smiles)\n",
    "\n",
    "    # Find duplicates and replace with mean\n",
    "    data = data.groupby('SMILES').agg({'affinity': 'mean'}).reset_index()\n",
    "    data[\"target\"] = name\n",
    "\n",
    "    # Calculate top 2% active compounds\n",
    "    number_top_2p = round(len(data) * 0.02)\n",
    "    top_2p = data.sort_values(by='affinity', ascending=False)[:number_top_2p].index   \n",
    "    data['top_2p'] = False\n",
    "    data.loc[top_2p, 'top_2p'] = True\n",
    "\n",
    "    # do the same for top 5%\n",
    "    number_top_5p = round(len(data) * 0.05)\n",
    "    top_5p = data.sort_values(by='affinity', ascending=False)[:number_top_5p].index\n",
    "    data[\"top_5p\"] = False\n",
    "    data.loc[top_5p, 'top_5p'] = True\n",
    "\n",
    "    # pre-featurise\n",
    "    f = Featuriser(smiles_col=\"SMILES\", presets=\"ECFP8\")\n",
    "    data[\"fps\"] = f.featurise(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from typing import Callable\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def standardise_smiles(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        return Chem.MolToSmiles(mol)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def load_dataset(name: str, path: str, smiles_col: str, affinity_col: str, affinity_conversion: Callable) -> pd.DataFrame:\n",
    "    # Load data\n",
    "    data = pd.read_csv(path)\n",
    "\n",
    "    # Convert affinity to pXC50 scale\n",
    "    data['affinity'] = affinity_conversion(data[affinity_col])\n",
    "\n",
    "    # Standardise column names and deduplicate\n",
    "    data = data.rename(columns={smiles_col: 'SMILES'})\n",
    "    data[\"SMILES\"] = data.SMILES.apply(standardise_smiles)\n",
    "\n",
    "    # Remove None values after standardisation\n",
    "    data = data.dropna(subset=[\"SMILES\"])\n",
    "\n",
    "    # Find duplicates and replace with mean\n",
    "    data = data.groupby('SMILES').agg({'affinity': 'mean'}).reset_index()\n",
    "    data[\"target\"] = name\n",
    "\n",
    "    # Calculate top 2% and 5% active compounds\n",
    "    data['top_2p'] = False\n",
    "    data.loc[data['affinity'].nlargest(round(len(data) * 0.02)).index, 'top_2p'] = True\n",
    "    data[\"top_5p\"] = False\n",
    "    data.loc[data['affinity'].nlargest(round(len(data) * 0.05)).index, 'top_5p'] = True\n",
    "\n",
    "    # Featurise using RDKit (ECFP8 with radius=4)\n",
    "    def get_ecfp8(smiles):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol:\n",
    "            ecfp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=4, nBits=4096)\n",
    "            return np.array(ecfp)\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    data[\"fps\"] = data.SMILES.apply(get_ecfp8)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exs.ale.models import GPModel, GenericModel,ChempropModel\n",
    "from exs.mtl_bundle.models.chemprop import model_config as chemprop_config\n",
    "\n",
    "def get_model(type: str, df_train: pd.DataFrame) -> GenericModel:\n",
    "    if type == \"GP\":\n",
    "        return GPModel(X_col='fps', y_col='affinity')\n",
    "    elif type == \"CP\":  # Chemprop\n",
    "               \n",
    "        model_args = {\n",
    "                    'model_name': \"ale_chemprop\",\n",
    "                    'fit_args': chemprop_config,\n",
    "                    'save_to_s3': False,\n",
    "                    'batch_size': 50,\n",
    "                    'num_epochs': 50,\n",
    "                    'eval_metric': \"r2\",\n",
    "                    'init_lr': 0.0001,\n",
    "                    'max_lr': 0.001,\n",
    "                    'final_lr': 0.0001,\n",
    "                    'warmup_epochs': 5,\n",
    "                    'encoder_from_pretrained_path': os.path.join(wd, \"pretrained/chemprop_model.bin\"),\n",
    "                    'freeze_encoder': False,\n",
    "                    'df_val': df_train.copy(),\n",
    "                    'silence': True,\n",
    "                    'num_epochs': 500,\n",
    "                    'warmup_epochs': 10,\n",
    "                }\n",
    "\n",
    "        return ChempropModel(X_col='SMILES', y_col='affinity', **model_args)\n",
    "#         raise Exception(\"Chemprop not defined yet\")\n",
    "    else:\n",
    "        raise Exception(f\"Unknown model type: {type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exs.ale.selectors import RandomSelector, UCBSelector\n",
    "\n",
    "def get_selector(type: str, seed: int) -> Callable:\n",
    "    if type == \"random\":\n",
    "        return RandomSelector(seed=seed)\n",
    "    elif type == \"explore\":\n",
    "        return UCBSelector(pred_col=\"pred\", std_col=\"std\", alpha=0, beta=1)\n",
    "    elif type == \"exploit\":\n",
    "        return UCBSelector(pred_col=\"pred\", std_col=\"std\", alpha=1, beta=0)\n",
    "    else:\n",
    "        raise Exception(f\"Unknown selector type: {type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List\n",
    "from exs.ale.models import NoModel\n",
    "from exs.ale.pipelines import ALPipelineDev, MulticycleAnalysis\n",
    "\n",
    "def selected_in_cycle(row):\n",
    "    sets = row.set.tolist()\n",
    "    try:\n",
    "        return sets.index('selection')\n",
    "    except:\n",
    "        return 'None'\n",
    "\n",
    "def active_learning(data: pd.DataFrame, selection_protocol: List[Any], model_type: str, seed: int):\n",
    "\n",
    "    # set up initial train/pool\n",
    "    train = pd.DataFrame(columns=data.columns)\n",
    "    pool = data.copy()\n",
    "    print(model_type)\n",
    "    # Set up the pipeline\n",
    "    if model_type == \"CP\":\n",
    "        print('SMILES')\n",
    "        al_featuriser = Featuriser(fps_col=\"SMILES\")\n",
    "    else:\n",
    "        al_featuriser = Featuriser(fps_col=\"fps\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Run AL\n",
    "    for cycle, (selector_type, batch_size) in enumerate(selection_protocol):\n",
    "\n",
    "        if cycle == 0:\n",
    "            al_model = NoModel(X_col=\"fps\", y_col=\"affinity\")\n",
    "        else:\n",
    "            al_model = get_model(model_type, train)\n",
    "\n",
    "        al_selector = get_selector(selector_type, seed)    \n",
    "        al_pipeline = ALPipelineDev(al_model, al_selector, al_featuriser, batch_size)\n",
    "        al_pipeline.set_data(train, pool) \n",
    "        \n",
    "        al_pipeline.run()\n",
    "\n",
    "        combined_df = al_pipeline.outputs[\"combined_df\"].copy()\n",
    "        combined_df.drop(columns=[\"index\"], inplace=True)\n",
    "        results.append(combined_df)\n",
    "\n",
    "        train = al_pipeline.outputs[\"train_new\"].copy()\n",
    "        pool = al_pipeline.outputs[\"pool_new\"].copy()\n",
    "\n",
    "    # Make a df with all cycles combined\n",
    "    for cycle, res in enumerate(results):\n",
    "        results[cycle]['cycle'] = cycle\n",
    "\n",
    "    # run multicycle analysis\n",
    "    multi_ana = MulticycleAnalysis(label_col=\"affinity\", clean_data=False, orion_compat=False)\n",
    "    multi_ana.set_data(results)\n",
    "    multi_ana.run()\n",
    "\n",
    "    all_data = pd.concat(results)\n",
    "    index=[\"SMILES\", \"affinity\", \"top_2p\", \"top_5p\"]\n",
    "    data_pivot = all_data.pivot(index=index, columns=[\"cycle\"], values=[\"pred\", \"std\", \"set\"]).reset_index()\n",
    "    data_pivot[\"selected_in_cycle\"] = data_pivot.apply(selected_in_cycle, axis=1)\n",
    "    \n",
    "    return data_pivot, multi_ana.outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of top 2% cpds in a randomly selected batch of num_acquired cpds\n",
    "from typing import Any, List\n",
    "\n",
    "def cycles_to_cpds(protocol: List[Any], cycle: str) -> int:\n",
    "    try:\n",
    "        return sum([p[1] for p in protocol[:cycle]])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_baseline(protocol: List[Any], cycle: str, percent: float):\n",
    "    try:\n",
    "        cpds_acquired = sum([p[1] for p in protocol[:cycle]])\n",
    "        return 0.01 * percent * cpds_acquired\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def normalise_recall(top_N: float, baseline_N: float, total_N: int):\n",
    "    try:\n",
    "        return (top_N - baseline_N) / (total_N - baseline_N)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def tag_dataset(df: pd.DataFrame, dataset: str, model: str, protocol_name: str, seed: int) -> pd.DataFrame:\n",
    "    df[\"Dataset\"] = dataset\n",
    "    df[\"Model\"] = model\n",
    "    df[\"Protocol\"] = protocol_name\n",
    "    df[\"seed\"] = seed\n",
    "    return df\n",
    "\n",
    "def do_analysis(res_df: pd.DataFrame, ana: pd.DataFrame, dataset: str, model: str, protocol_name: str, \n",
    "                protocol: List[Any], seed: int) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \n",
    "    # calculate top 2% and 5% recall\n",
    "    sel_2 = res_df.groupby('selected_in_cycle').top_2p.sum().reset_index()\n",
    "    sel_5 = res_df.groupby('selected_in_cycle').top_5p.sum().reset_index()\n",
    "    recall = sel_2.merge(sel_5, on=\"selected_in_cycle\")\n",
    "    recall = tag_dataset(recall, dataset, model, protocol_name, seed)\n",
    "    recall[\"compounds_acquired\"] = recall.selected_in_cycle.apply(lambda x: cycles_to_cpds(protocol, x))\n",
    "    recall[\"top_2p_cum\"] = np.cumsum(recall.top_2p)\n",
    "    recall[\"top_5p_cum\"] = np.cumsum(recall.top_5p)\n",
    "    recall[\"baseline_2p\"] = recall.selected_in_cycle.apply(lambda x: get_baseline(protocol, x, 2))\n",
    "    recall[\"baseline_5p\"] = recall.selected_in_cycle.apply(lambda x: get_baseline(protocol, x, 5))\n",
    "    recall[\"normalised_2p\"] = recall.apply(lambda row: normalise_recall(row.top_2p_cum, row.baseline_2p, res_df.top_2p.sum()), axis=1)\n",
    "    recall[\"normalised_5p\"] = recall.apply(lambda row: normalise_recall(row.top_5p_cum, row.baseline_5p, res_df.top_5p.sum()), axis=1)\n",
    "\n",
    "    # metrics\n",
    "    metrics = ana[\"retrospective_metrics_metrics_df\"].reset_index()\n",
    "    metrics = tag_dataset(metrics, dataset, model, protocol_name, seed)\n",
    "    metrics[\"compounds_acquired\"] = metrics.cycle.apply(lambda x: cycles_to_cpds(protocol, x))\n",
    "\n",
    "    return recall, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exs.ale.analysis.plot_chemical_space import plot_chemical_space\n",
    "import pickle\n",
    "\n",
    "def plot_cpds_found_on_fmap(results: pd.DataFrame, dataset: str, set = \"top_2p\", model=None, protocol_name=None, noise_level=None, ax=None, xlabel=None, ylabel=None, legend=False, cycle=None):\n",
    "\n",
    "    df = results[results.Dataset == dataset].reset_index(drop=True)\n",
    "\n",
    "    if model is not None:\n",
    "        df = df[df.Model == model].reset_index(drop=True)\n",
    "\n",
    "    if protocol_name is not None:\n",
    "        df = df[df.Protocol == protocol_name].reset_index(drop=True)\n",
    "\n",
    "    if noise_level is not None:\n",
    "        df = df[df.noise_level == noise_level].reset_index(drop=True)\n",
    "\n",
    "    df = df.dropna(axis=\"columns\")\n",
    "\n",
    "    df[\"selected\"] = 0\n",
    "    if cycle is None:\n",
    "        n_cycles = len(df.set.columns)-1\n",
    "    else: \n",
    "        n_cycles = cycle\n",
    "    df.loc[df[(\"set\", n_cycles)] == \"train\", \"selected\"] = 1\n",
    "\n",
    "    df = df.groupby([\"SMILES\"]).mean().reset_index()\n",
    "    df = df.sort_values(by=\"SMILES\").reset_index(drop=True)\n",
    "    df[\"selected\"] = df.selected.apply(lambda x: round(x, 2))\n",
    "\n",
    "    df.loc[df.top_2p == False, \"selected\"]  = -1\n",
    "\n",
    "    with open(f\"data/feature_maps/{dataset}.pkl\", \"rb\") as fmap_file:\n",
    "        feature_map = pickle.load(fmap_file)\n",
    "\n",
    "    levels = len(df.selected.unique()) - 1\n",
    "    zorder_sel ={k/(levels-1)+1: k for k in range(levels)}\n",
    "    zorder = {\"not in top 2%\": 0, **zorder_sel}\n",
    "\n",
    "    plot_chemical_space(df, feature_map, set_col=\"selected\",  \\\n",
    "                    set_colors={-1: \"gray\"}, zorder=zorder, cmap=\"copper_r\", markersize=10, ax=ax, labels={-1: \"not in top 2%\"}, set_markersize=10, xlabel=xlabel, ylabel=ylabel, legend=legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#plt.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def make_recall_for_plot(recall: pd.DataFrame, total_2p: Dict, total_5p: Dict) -> pd.DataFrame:\n",
    "\n",
    "    recall_for_plot = recall[(recall.selected_in_cycle != \"None\") & (recall.Protocol != \"random-explore\")].reset_index()\n",
    "\n",
    "    for percent, total_p in zip([2,5], [total_2p, total_5p]):\n",
    "        recall_for_plot[f\"F1 ({percent}%)\"] = recall_for_plot.apply(lambda row: 2*row[f\"top_{percent}p_cum\"] / (row.compounds_acquired + total_p[row.Dataset]), axis=1)\n",
    "        recall_for_plot[f\"Recall ({percent}%)\"] = recall_for_plot.apply(lambda row: row[f\"top_{percent}p_cum\"] / total_p[row.Dataset], axis=1)\n",
    "\n",
    "        batch = np.linspace(60, 360, 11)\n",
    "\n",
    "        for dataset, n_total in total_p.items():\n",
    "            for acquired in batch:\n",
    "                for model in recall_for_plot.Model.unique():\n",
    "                    recall_for_plot.loc[len(recall_for_plot)] = {\n",
    "                        \"Dataset\": dataset,\n",
    "                        \"Model\": model,\n",
    "                        \"Protocol\": \"Baseline\",\n",
    "                        \"noise_level\": \"Baseline\",\n",
    "                        \"compounds_acquired\": acquired,\n",
    "                        f\"Recall ({percent}%)\": 0.01 * percent * acquired / n_total,\n",
    "                        f\"F1 ({percent}%)\": 0.01 * percent * acquired / (acquired + n_total)\n",
    "                    }\n",
    "\n",
    "    recall_for_plot.rename(columns={\"compounds_acquired\": \"Compounds acquired\"}, inplace=True)\n",
    "    #recall_for_plot.rename(columns={\"f1_2p\": r'$F_1$ (2%)', \"compounds_acquired\": r'$N_{acq}$'}, inplace=True)\n",
    "    return recall_for_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
